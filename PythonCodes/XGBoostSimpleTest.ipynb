{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.95%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# First XGBoost model for Pima Indians dataset\n",
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "# load data\n",
    "dataset = loadtxt('./data/pima-indians-diabetes.csv', delimiter=\",\")\n",
    "# split data into X and y\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# split data into train and test sets\n",
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "# fit model no training data\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy array precision: 1.0\n",
      "Svm file precision: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\i052090\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['bst_svm_model.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ieva Zarina, 2016, licensed under the Apache 2.0 licnese\n",
    "\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn import datasets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# use DMatrix for xgbosot\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# use svmlight file for xgboost\n",
    "dump_svmlight_file(X_train, y_train, 'dtrain.svm', zero_based=True)\n",
    "dump_svmlight_file(X_test, y_test, 'dtest.svm', zero_based=True)\n",
    "dtrain_svm = xgb.DMatrix('dtrain.svm')\n",
    "dtest_svm = xgb.DMatrix('dtest.svm')\n",
    "\n",
    "# set xgboost params\n",
    "param = {\n",
    "    'max_depth': 3,  # the maximum depth of each tree\n",
    "    'eta': 0.3,  # the training step for each iteration\n",
    "    'silent': 1,  # logging mode - quiet\n",
    "    'objective': 'multi:softprob',  # error evaluation for multiclass training\n",
    "    'num_class': 3}  # the number of classes that exist in this datset\n",
    "num_round = 20  # the number of training iterations\n",
    "\n",
    "#------------- numpy array ------------------\n",
    "# training and testing - numpy matrices\n",
    "bst = xgb.train(param, dtrain, num_round)\n",
    "preds = bst.predict(dtest)\n",
    "\n",
    "# extracting most confident predictions\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "print(\"Numpy array precision:\", precision_score(y_test, best_preds, average='macro'))\n",
    "\n",
    "# ------------- svm file ---------------------\n",
    "# training and testing - svm file\n",
    "bst_svm = xgb.train(param, dtrain_svm, num_round)\n",
    "preds = bst.predict(dtest_svm)\n",
    "\n",
    "# extracting most confident predictions\n",
    "best_preds_svm = [np.argmax(line) for line in preds]\n",
    "print(\"Svm file precision:\",precision_score(y_test, best_preds_svm, average='macro'))\n",
    "# --------------------------------------------\n",
    "\n",
    "# dump the models\n",
    "bst.dump_model('dump.raw.txt')\n",
    "bst_svm.dump_model('dump_svm.raw.txt')\n",
    "\n",
    "\n",
    "# save the models for later\n",
    "joblib.dump(bst, 'bst_model.pkl', compress=True)\n",
    "joblib.dump(bst_svm, 'bst_svm_model.pkl', compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
